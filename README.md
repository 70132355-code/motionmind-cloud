# MotionMind Cloud - Gesture Control Platform

AI-powered gesture control system with hand tracking using MediaPipe.

## ğŸ“ Project Structure

```
motionmind cloud/
â”œâ”€â”€ frontend/           # Firebase Hosting (HTML, CSS, JS)
â”‚   â”œâ”€â”€ index.html
â”‚   â”œâ”€â”€ script.js
â”‚   â”œâ”€â”€ config.js      # Backend URL configuration
â”‚   â””â”€â”€ firebase.json
â”‚
â”œâ”€â”€ backend/            # Render (Flask + MediaPipe)
â”‚   â”œâ”€â”€ app.py
â”‚   â”œâ”€â”€ mediapipe_compat.py
â”‚   â”œâ”€â”€ games/
â”‚   â””â”€â”€ requirements.txt
â”‚
â””â”€â”€ frontend_v6_firebase/  # (Old structure - ignore)
```

## ğŸš€ Deployment

### Frontend (Firebase)

```bash
cd frontend
firebase deploy
```

**Live URL**: https://motionmind-1d875.web.app

### Backend (Render)

1. Push to GitHub
2. Connect Render to repository
3. Set root directory: `backend`
4. Build: `pip install -r requirements.txt`
5. Start: `gunicorn app:app --bind 0.0.0.0:10000`

**API URL**: https://motionmind-cloud.onrender.com

## ğŸ”§ Configuration

After deploying backend, update frontend config:

**frontend/config.js**:
```javascript
const BACKEND_URL = 'https://motionmind-cloud.onrender.com';
```

Then redeploy frontend.

## ğŸ¥ How It Works

1. Browser captures camera frames via getUserMedia()
2. Frames sent to backend `/process-frame` endpoint
3. Backend processes with MediaPipe and returns gesture
4. Frontend updates UI based on detected gesture

**No server-side camera needed!**

## ğŸ“ Features

- âœ… Hand gesture detection
- âœ… Whiteboard drawing
- âœ… Gesture-controlled games
- âœ… Presentation control
- âœ… Firebase authentication

## ğŸ”‘ Firebase Project

- Project ID: `motionmind-1d875`
- Authentication: Email/Password enabled

## ğŸ“¦ Tech Stack

**Frontend**: HTML, CSS, JavaScript, Firebase Hosting  
**Backend**: Flask, MediaPipe, OpenCV, Gunicorn  
**Deployment**: Firebase + Render
